{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp feature_extraction.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_extraction.text\n",
    "\n",
    "> Basic feature extraction techniques for text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Resources :**\n",
    "- [A blog by Machine Learning Mastery](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)\n",
    "- [Sklearn Implementation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.sparse import coo_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy DataSet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [\"Sample one\", \"Sample one\", \"Sample one\"]\n",
    "x_train = [x.split() for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sample', 'one'], ['Sample', 'one'], ['Sample', 'one']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[\"Some\", \"b\", \"a\"], [\"a\", \"b\"], [\"c\", \"b\"], [\"d\", \"b\"]]\n",
    "x_test  = [[\"a\", \"e\"], [\"a\"], [\"c\", \"b\", \"b\"], [\"c\"]]\n",
    "y_train = [\"class 1\",\"class 1\",\"class 2\",\"class 3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CountVectorizer:\n",
    "    \"\"\"Implementation of Bag of Word Model. Assign zero to terms that don't occur in vocabulary\"\"\"\n",
    "    \n",
    "    def __init__(self, store_class_vocab = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            store_class_vocab (bool): store vocabulary for individual classes ?\n",
    "        \"\"\"\n",
    "        \n",
    "        if store_class_vocab:\n",
    "            self.store_class_vocab = {} \n",
    "        \n",
    "    def _calculate_stats(self, y_train):\n",
    "        \"\"\"Calculates basic stats: labels , labels frequency, and distrubution of labels/class\"\"\"\n",
    "        self.labels, self.labels_freq = np.unique(y_train, return_counts= True)\n",
    "        total_freq = np.sum(self.labels_freq)\n",
    "        self.distribution = self.labels_freq / total_freq\n",
    "        \n",
    "    def _get_vocab(self,  x_train, y_train):\n",
    "        \"\"\"Build vocabulary  and store corresponding frequency of word types\"\"\"\n",
    "        \n",
    "        vocab = Counter()\n",
    "        for label in self.labels:\n",
    "            vocab += self._word_to_count_map(x_train, y_train , label)\n",
    "        \n",
    "        self.vocab, self.vocab_freq = zip(*vocab.items())\n",
    "\n",
    "    def _word_to_count_map(self, x_train, y_train , label):\n",
    "        \"\"\"A dictionary that maps from word types in a class to its frequency\"\"\"\n",
    "        \n",
    "        word_to_count = defaultdict(int)\n",
    "        for index , sample in enumerate(x_train):\n",
    "            if y_train[index] == label:\n",
    "                for term in sample:\n",
    "                    word_to_count[term] += 1\n",
    "        \n",
    "        try: # can be used to store vocab of individual classes\n",
    "            self.store_class_vocab[label] = word_to_count \n",
    "        finally:\n",
    "            return Counter(word_to_count)\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"Calcultes neccesary stats to build Bag of Words model\"\n",
    "        \n",
    "        Args:\n",
    "            x_train (nested list): list of list containing samples.\n",
    "            y_train (list): labels for training samples.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._calculate_stats(y_train)\n",
    "        self._get_vocab(x_train, y_train)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"Make Bag of Words vector.\n",
    "        \n",
    "        Args:\n",
    "            X (nested list): list of list containing tokenized samples.\n",
    "            \n",
    "        Returns:\n",
    "            sparse coordinate matrix of shape(len(X), len(vocab))\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        columns = []\n",
    "        data = []\n",
    "        \n",
    "        for sample_index, sample in enumerate(X):\n",
    "            sample = Counter(sample)\n",
    "            for term, term_freq in sample.items():\n",
    "                if term in self.vocab:\n",
    "                    vocab_index = self.vocab.index(term)\n",
    "                else:  #assign zero to some new term in test set which is not present in train.\n",
    "                    continue\n",
    "                columns.append(vocab_index)\n",
    "                rows.append(sample_index)\n",
    "                data.append(term_freq)\n",
    "       \n",
    "        return coo_matrix((data,(rows, columns)), shape=(len(X), len(self.vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv =  CountVectorizer(store_class_vocab = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# cv._calculate_stats(y_train)\n",
    "\n",
    "# cv.labels, cv.labels_freq, cv.distribution\n",
    "\n",
    "# cv._word_to_count_map(x_train, y_train, label = 3)\n",
    "\n",
    "# cv._get_vocab( x_train, y_train)\n",
    "\n",
    "# cv.vocab, cv.vocab_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'b', 'c', 'd')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class 1': defaultdict(int, {'a': 3, 'b': 2}),\n",
       " 'class 2': defaultdict(int, {'c': 1, 'b': 1}),\n",
       " 'class 3': defaultdict(int, {'d': 1, 'b': 1})}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.store_class_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = cv.transform(x_train).tocsr() \n",
    "x_test = cv.transform(x_test).tocsr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 2, 1, 0],\n",
       "       [0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_count_vectorizer.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted main.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
